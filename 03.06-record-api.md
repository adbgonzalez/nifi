# 03.06 NiFi Record API — Guía Definitiva

O **Record API** é o mecanismo moderno de Apache NiFi para traballar con datos estruturados, permitindo procesar rexistros de forma eficiente e profesional.

---

# 1. Por que existe o Record API?

Antes, procesar datos estruturados requiría ferramentas como:
- SplitText
- ReplaceText
- ExtractText
- Regex complexas
- MergeContent

Isto era pouco eficiente e difícil de manter.

O Record API permite:
- Transformación rexistro a rexistro
- Conversión entre formatos (CSV, JSON, Avro, Parquet…)
- Filtrado con SQL-like (QueryRecord)
- Validación mediante esquemas (ValidateRecord)
- Mellor integración con Kafka, Spark, HDFS e MinIO

---

# 2. Componentes principais do Record API

```
Record Reader  →  Procesador ETL  →  Record Writer
```

---

# 3. Record Readers

## 3.1. JsonTreeReader
Lector estándar para JSON obxecto e JSON array.

### Propiedades destacadas
- Schema Access Strategy (Infer, Embedded…)
- Soporte para tipos complexos
- Supresión opcional de valores nulos

---

## 3.2. CSVReader
Lector para CSV estruturado.

### Propiedades destacadas
- First Line Header (true/false)
- Delimiter
- Schema Access Strategy

---

## 3.3. AvroReader
Lector eficiente para formatos Avro. Útil en pipelines Kafka–Spark–HDFS.

---

## 3.4. JsonPathReader
Permite extraer rexistros desde JSON mediante JSONPath.

---

# 4. Record Writers

## 4.1. JsonRecordSetWriter
Xera saída JSON estruturada.

## 4.2. CSVRecordSetWriter
Transforma os rexistros de saída nun CSV estándar.

## 4.3. AvroRecordSetWriter
Moito máis eficiente para datos grandes e integración con Spark/HDFS.

## 4.4. ParquetRecordSetWriter (opcional)
Requere extensión NAR adicional.

---

# 5. Procesadores ETL baseados en Record API

## 5.1. ConvertRecord — O máis importante
Converter formatos estruturados.

Exemplos:
- CSV → JSON
- JSON → Avro
- Avro → Parquet
- JSON → CSV

Funciona con:
- Record Reader (entrada)
- Record Writer (saída)

---

## 5.2. UpdateRecord
Modificar valores de campos.

Exemplos:
```
/campo = ${campo:trim()}
```

```
/ts_ingestion = ${now():toNumber()}
```

---

## 5.3. QueryRecord
Permite aplicar SQL-like sobre os rexistros.

Exemplo:
```
SELECT * FROM FLOWFILE WHERE temperatura > 20
```

Cada consulta crea a súa propia relación de saída.

---

## 5.4. ValidateRecord
Validación de rexistros mediante un esquema Avro.

Usos comúns:
- Validación de APIs
- Validación antes de Kafka
- Validación antes de SQL/ETL

---

## 5.5. JoltTransformRecord
Transformación avanzada con JOLT para JSON complexos.

---

# 6. Exemplo profesional: API → Kafka → HDFS

```
HandleHttpRequest
  → ValidateRecord
  → UpdateRecord
  → PublishKafkaRecord
```

Pipeline downstream:
```
ConsumeKafkaRecord
  → ConvertRecord (JSON → Parquet)
  → PutHDFS
```

---

# 7. Exemplo práctico: CSV → JSON → MinIO

```
ListFile
  → FetchFile
  → ConvertRecord (CSVReader → JsonRecordSetWriter)
  → PutS3Object
```

---

# 8. Boas prácticas

- Usar sempre esquemas Avro cando sexa posible.
- JsonTreeReader para JSON.
- Avro/Parquet para volumes grandes.
- Non mesturar ReplaceText con Record API.
- Usar UpdateRecord para transformacións en vez de ReplaceText.

---

# 9. Checklist para o alumnado

- Sei configurar un RecordReader?
- Sei configurar un RecordWriter?
- Sei converter CSV → JSON?
- Sei filtrar rexistros con QueryRecord?
- Sei engadir campos con UpdateRecord?
- Sei validar esquemas con ValidateRecord?

---

